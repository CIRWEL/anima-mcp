[project]
name = "anima-mcp"
version = "1.0.0"
description = "An embodied AI creature running on Raspberry Pi with real sensors and persistent identity"
readme = "README.md"
requires-python = ">=3.11"
license = {text = "MIT"}
authors = [
    {name = "CIRWEL"}
]
keywords = ["mcp", "raspberry-pi", "embodied-ai", "creature", "sensors", "anima", "lumen"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
]

dependencies = [
    "mcp>=1.26.0,<2.0.0",
    "pyyaml>=6.0,<7.0",
    "psutil>=5.9.0,<6.0.0",
    "Pillow>=10.0.0,<11.0.0",
    "aiohttp>=3.9.0,<4.0.0",
    "starlette>=0.35.0,<1.0.0",
    "uvicorn>=0.25.0,<1.0.0",
]

[project.optional-dependencies]
pi = [
    # GPIO
    "RPi.GPIO>=0.7.1,<1.0.0",
    # I2C communication
    "adafruit-circuitpython-busdevice>=5.2.0,<6.0.0",
    "adafruit-circuitpython-register>=1.9.0,<2.0.0",
    # Sensors
    "adafruit-circuitpython-ahtx0>=1.0.0,<2.0.0",
    "adafruit-circuitpython-veml7700>=1.1.0,<2.0.0",
    "adafruit-circuitpython-bmp280>=3.2.0,<4.0.0",
    # Display - numpy required for fast RGB565 conversion (10x speedup)
    "adafruit-circuitpython-rgb-display>=3.11.0,<4.0.0",
    "adafruit-circuitpython-st7789>=1.6.0,<2.0.0",
    "numpy>=1.24.0,<3.0.0",
    # LEDs
    "adafruit-circuitpython-dotstar>=2.2.0,<3.0.0",
]

brain = [
    # OpenBCI Brain HAT support (optional)
    "brainflow>=5.0.0,<6.0.0",
    "numpy>=1.24.0,<2.0.0",
    "scipy>=1.10.0,<2.0.0",
]

audio = [
    # Audio support (future feature)
    "pyaudio>=0.2.13,<1.0.0",
    "SpeechRecognition>=3.10.0,<4.0.0",
]

dev = [
    "pytest>=7.4.0,<8.0.0",
    "pytest-asyncio>=0.21.0,<1.0.0",
    "pytest-cov>=4.1.0,<5.0.0",
    "black>=23.7.0,<24.0.0",
    "ruff>=0.0.285,<1.0.0",
    "mypy>=1.5.0,<2.0.0",
    "types-PyYAML>=6.0.0,<7.0.0",
    "types-psutil>=5.9.0,<6.0.0",
]

# Convenience: Install everything for Pi
all = [
    "anima-mcp[pi,brain,audio,dev]",
]

[project.scripts]
anima = "anima_mcp.server:main"
anima-creature = "anima_mcp.stable_creature:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.pytest.ini_options]
pythonpath = ["src"]
testpaths = ["tests"]
asyncio_mode = "auto"
asyncio_default_fixture_loop_scope = "function"

[tool.coverage.run]
source = ["anima_mcp"]
omit = ["*/tests/*", "*/art_movements/*"]

[tool.coverage.report]
show_missing = true
exclude_lines = [
    "pragma: no cover",
    "if __name__",
    "if TYPE_CHECKING",
    "raise NotImplementedError",
]

[tool.hatch.build.targets.wheel]
packages = ["src/anima_mcp"]
